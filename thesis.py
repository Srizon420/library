# -*- coding: utf-8 -*-
"""Thesis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E6j0h3Aofdf8QB1oZ1Jir44nl7pxEYR9
"""

from google.colab import drive

drive.mount('/content/drive')

"""#import libraries"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import numpy as num
import matplotlib.pyplot as plot

"""#Reading CSV file using panda

#Info about the data shape of data, type of individual columns
"""

data = pd.read_csv("/content/drive/MyDrive/soccer - Sheet1.csv")
data.head()

data.info()

data.shape

"""Selecting Feature selection"""

data.columns

data = data[['Venue', 'Opponent','GF', 'GA', 'xG','xGA', 'Poss', 'Result']]

data['Result'].value_counts()

data['Result'].values

# Check if there is any null value
data.isna().apply(pd.value_counts)

#Check for number of null values
data.isnull().sum()

#Check if any duplicate rows in dataset
data.duplicated().sum()

data['Result'].value_counts()

data['Result'].values

"""#making categorical data into numerical data by using encoder"""

from sklearn.preprocessing import LabelEncoder

label = LabelEncoder()
data['Venue'] = label.fit_transform(data['Venue'])
data['Opponent'] = label.fit_transform(data['Opponent'])
data['Result'] = label.fit_transform(data['Result'])

from sklearn.model_selection import train_test_split

X = data[['Venue', 'Opponent','GF', 'GA', 'xG', 'xGA', 'Poss']].values
Y = data[['Result']].values

X

"""Here, Win=2
      Draw=0
      Lose=1
"""

Y

X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=0.20)

X_train.shape, X_test.shape, Y_train.shape, Y_test.shape

"""Logistic Regression"""

from sklearn.linear_model import LogisticRegression

LR = LogisticRegression()

LR.fit(X_train, Y_train)

Y_pred = LR.predict(X_test)

Y_test = Y_test.flatten()
Y_pred = Y_pred.flatten()

Y_test.shape, Y_pred.shape

data_lgr = pd.DataFrame({'Y_test': Y_test , 'Y_pred': Y_pred}) 
data_lgr

from sklearn.metrics import classification_report, confusion_matrix,accuracy_score

print(confusion_matrix(Y_test, Y_pred))
print("Report",classification_report(Y_test, Y_pred))
print("Accuracy of Logistic Regression =",accuracy_score(Y_test,Y_pred))

cm = confusion_matrix(Y_test,Y_pred)
sns.heatmap(cm,annot=True,fmt="d")

# Plot confusion matrix
conf_mat = confusion_matrix(Y_test, Y_pred)

#Normalize confusion_matrix
conf_mat = conf_mat.astype('float')/ conf_mat.sum(axis=1)[:, np.newaxis]

# Plot Heat Map
fig , ax = plt.subplots()
fig.set_size_inches(8, 4)
sns.heatmap(conf_mat)

"""K Nearest Neighbors**"""

from sklearn.neighbors import KNeighborsClassifier

KNN = KNeighborsClassifier()

KNN.fit(X_train,Y_train)

Y_pred = KNN.predict(X_test)

Y_test = Y_test.flatten()
Y_pred = Y_pred.flatten()

data_knn = pd.DataFrame({'Y_test': Y_test , 'Y_pred': Y_pred}) 
data_knn

print(confusion_matrix(Y_test, Y_pred))
print("Report",classification_report(Y_test, Y_pred))
print("Accuracy of KNN =",accuracy_score(Y_test,Y_pred))
cm = confusion_matrix(Y_test,Y_pred)
sns.heatmap(cm,annot=True,fmt="d")

# Plot confusion matrix
conf_mat = confusion_matrix(Y_test, Y_pred)

#Normalize confusion_matrix
conf_mat = conf_mat.astype('float')/ conf_mat.sum(axis=1)[:, np.newaxis]

# Plot Heat Map
fig , ax = plt.subplots()
fig.set_size_inches(8, 4)
sns.heatmap(conf_mat)

""" Random Forest Algorithm**"""

from sklearn.ensemble import RandomForestClassifier

RF = RandomForestClassifier(n_estimators=5)

RF.fit(X_train, Y_train)

Y_pred = RF.predict(X_test)

Y_test = Y_test.flatten()
Y_pred = Y_pred.flatten()

data_rfc = pd.DataFrame({'Y_test': Y_test , 'Y_pred': Y_pred}) 
data_rfc

print(confusion_matrix(Y_test, Y_pred))
print("Report",classification_report(Y_test, Y_pred))
print("Accuracy of Random Forest =",accuracy_score(Y_test,Y_pred))
cm = confusion_matrix(Y_test,Y_pred)
sns.heatmap(cm,annot=True,fmt="d")

# Plot confusion matrix
conf_mat = confusion_matrix(Y_test, Y_pred)

#Normalize confusion_matrix
conf_mat = conf_mat.astype('float')/ conf_mat.sum(axis=1)[:, np.newaxis]

# Plot Heat Map
fig , ax = plt.subplots()
fig.set_size_inches(8, 4)
sns.heatmap(conf_mat)

"""SVM

"""

from sklearn.svm import SVC

SVM= SVC(kernel = 'linear', random_state = 0)

SVM.fit(X_train,Y_train)

Y_pred = SVM.predict(X_test)

Y_test = Y_test.flatten()
Y_pred = Y_pred.flatten()

data_DT = pd.DataFrame({'Y_test': Y_test , 'Y_pred': Y_pred}) 
data_DT

print(confusion_matrix(Y_test, Y_pred))
print("Report",classification_report(Y_test, Y_pred))
print("Accuracy of SVM =",accuracy_score(Y_test,Y_pred))
cm = confusion_matrix(Y_test,Y_pred)
sns.heatmap(cm,annot=True,fmt="d")

# Plot confusion matrix
conf_mat = confusion_matrix(Y_test, Y_pred)

#Normalize confusion_matrix
conf_mat = conf_mat.astype('float')/ conf_mat.sum(axis=1)[:, np.newaxis]

# Plot Heat Map
fig , ax = plt.subplots()
fig.set_size_inches(8, 4)
sns.heatmap(conf_mat)

"""**5)Decision Tree**"""

from sklearn.tree import DecisionTreeClassifier

DTclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)

DTclassifier.fit(X_train, Y_train)

Y_pred=DTclassifier.predict(X_test)

Y_test=Y_test.flatten()
Y_pred= Y_pred.flatten()

df_DT = pd.DataFrame({'Y_test': Y_test , 'Y_pred': Y_pred}) 
df_DT

print(confusion_matrix(Y_test, Y_pred))
print("Report",classification_report(Y_test, Y_pred))
print("Accuracy of Decision Tree =",accuracy_score(Y_test,Y_pred))
cm = confusion_matrix(Y_test,Y_pred)
sns.heatmap(cm,annot=True,fmt="d")

# Plot confusion matrix
conf_mat = confusion_matrix(Y_test, Y_pred)

#Normalize confusion_matrix
conf_mat = conf_mat.astype('float')/ conf_mat.sum(axis=1)[:, np.newaxis]

# Plot Heat Map
fig , ax = plt.subplots()
fig.set_size_inches(8, 4)
sns.heatmap(conf_mat)

"""Naive Bayes"""

from sklearn.naive_bayes import MultinomialNB

model = MultinomialNB()

model.fit(X_train,Y_train)

Y_pred = model.predict(X_test)

Y_test=Y_test.flatten()
Y_pred= Y_pred.flatten()

data_MNB = pd.DataFrame({'Y_test': Y_test , 'Y_pred': Y_pred}) 
data_MNB

print(confusion_matrix(Y_test, Y_pred))
print("Report",classification_report(Y_test, Y_pred))
accuracy_score(Y_test,Y_pred)
print("Accuracy of Naive Bayes =",accuracy_score(Y_test,Y_pred))
cm = confusion_matrix(Y_test,Y_pred)
sns.heatmap(cm,annot=True,fmt="d")

# Plot confusion matrix
conf_mat = confusion_matrix(Y_test, Y_pred)

#Normalize confusion_matrix
conf_mat = conf_mat.astype('float')/ conf_mat.sum(axis=1)[:, np.newaxis]

# Plot Heat Map
fig , ax = plt.subplots()
fig.set_size_inches(8, 4)
sns.heatmap(conf_mat)

import matplotlib.pyplot as plt

data = {'K-NN': 68, 'RF': 95,'DT':99,'NB': 78}

names = list(data.keys())
values = list(data.values())


fig, axs = plt.subplots(1, 2, figsize=(16, 8), sharey=True)

axs[0].bar(names, values)
plt.xlabel('Algorithms')
plt.ylabel('Accuracy')
axs[1].scatter(names, values)

fig.suptitle('Comparision of Accuracy')

data1 = {'K-NN': 68, 'RF': 95,'DT':99,'NB': 78}
names1 = list(data1.keys())
values1 = list(data1.values())
plt.subplots(figsize=(10, 6))
plt.ylabel('Algorithms')
plt.xlabel('F1-Score')


plt.grid(color='black', linestyle='dashed', linewidth=1)
plt.barh(names1, values1)

print("sample input =",X_test)